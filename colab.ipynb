{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"colab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZc9WpozvkWq","executionInfo":{"status":"ok","timestamp":1647508682226,"user_tz":420,"elapsed":16667,"user":{"displayName":"Ziqing Zhong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09288499055193360161"}},"outputId":"89ee1eea-baaf-4ccc-bbbe-5faf66b8ba7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Installing collected packages: colorama\n","Successfully installed colorama-0.4.4\n","Collecting tensorly\n","  Downloading tensorly-0.7.0-py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 4.1 MB/s \n","\u001b[?25hCollecting nose\n","  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n","\u001b[K     |████████████████████████████████| 154 kB 40.0 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.21.5)\n","Installing collected packages: nose, tensorly\n","Successfully installed nose-1.3.7 tensorly-0.7.0\n","Collecting tensorly-torch\n","  Downloading tensorly_torch-0.3.0-py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 885 kB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensorly-torch) (1.4.1)\n","Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from tensorly-torch) (1.3.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorly-torch) (1.21.5)\n","Installing collected packages: tensorly-torch\n","Successfully installed tensorly-torch-0.3.0\n"]}],"source":["!pip install colorama\n","!pip install -U tensorly\n","!pip install -U tensorly-torch"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab-Notebooks/tensor_adapt_165\n","# %cd /content/drive/MyDrive/courses/CS165/tensor_adapt\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PA4TIHrvsdw","executionInfo":{"status":"ok","timestamp":1647510470769,"user_tz":420,"elapsed":2057,"user":{"displayName":"Ziqing Zhong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09288499055193360161"}},"outputId":"1c0e55df-9a27-465d-9ccb-b96fb447c427"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab-Notebooks/tensor_adapt_165\n"]}]},{"cell_type":"markdown","source":["### Debug\n"],"metadata":{"id":"pe6zk_upiJeS"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab-Notebooks/tensor_adapt_165\n","\n","from __future__ import print_function\n","import argparse\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from utils.misc import *\n","from utils.test_helpers_TTT import *\n","from utils.prepare_dataset import *\n","from utils.rotation import rotate_batch\n","from utils.load_weights_ckp import *\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--dataset', default='cifar10')\n","parser.add_argument('--dataroot', default='datasets/')\n","parser.add_argument('--shared', default='layer2')\n","########################################################################\n","parser.add_argument('--depth', default=26, type=int)\n","parser.add_argument('--width', default=1, type=int)\n","parser.add_argument('--batch_size', default=128, type=int)\n","parser.add_argument('--group_norm', default=8, type=int)\n","parser.add_argument('--tensor', default=True)\n","########################################################################\n","parser.add_argument('--lr', default=0.1, type=float)\n","parser.add_argument('--nepoch', default=150, type=int)\n","parser.add_argument('--milestone_1', default=75, type=int)\n","parser.add_argument('--milestone_2', default=125, type=int)\n","parser.add_argument('--rotation_type', default='expand')\n","########################################################################\n","parser.add_argument('--outf', default='.')\n","\n","args = parser.parse_args(args=[])\n","\n","#cudnn.benchmark = True\n","net, ext, head, ssh = build_model_modules(args)\n","_, teloader = prepare_test_data(args)\n","_, trloader = prepare_train_data(args)\n","\n","parameters = list(net.parameters()) + list(head.parameters())\n","optimizer = optim.SGD(parameters, lr=args.lr, momentum=0.9, weight_decay=5e-4)\n","\n","print(\"net's state_dict:\")\n","for param_tensor in net.state_dict():\n","    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"caaXV4CBh_Bw","executionInfo":{"status":"error","timestamp":1647508711540,"user_tz":420,"elapsed":11550,"user":{"displayName":"Ziqing Zhong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09288499055193360161"}},"outputId":"4aac15aa-1901-42ef-90c2-45931ae70110"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab-Notebooks/tensor_adapt_165\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-7f742d3b6c94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrotate_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_ckp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_ckp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.save_model'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab-Notebooks/tensor_adapt_165\n","\n","from __future__ import print_function\n","import argparse\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","from utils.misc import *\n","from utils.test_helpers_TTT import *\n","from utils.prepare_dataset import *\n","from utils.rotation import rotate_batch\n","from utils.load_weights_ckp import *\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--dataset', default='cifar10')\n","parser.add_argument('--dataroot', default='datasets/')\n","parser.add_argument('--shared', default='layer2')\n","########################################################################\n","parser.add_argument('--depth', default=26, type=int)\n","parser.add_argument('--width', default=1, type=int)\n","parser.add_argument('--batch_size', default=128, type=int)\n","parser.add_argument('--group_norm', default=8, type=int)\n","parser.add_argument('--tensor', default=True)\n","########################################################################\n","parser.add_argument('--lr', default=0.1, type=float)\n","parser.add_argument('--nepoch', default=150, type=int)\n","parser.add_argument('--milestone_1', default=75, type=int)\n","parser.add_argument('--milestone_2', default=125, type=int)\n","parser.add_argument('--rotation_type', default='rand')\n","########################################################################\n","parser.add_argument('--outf', default='.')\n","\n","args = parser.parse_args(args=[])\n","\n","net, ext, head, ssh = build_model_modules(args)\n","_, teloader = prepare_test_data(args)\n","_, trloader = prepare_train_data(args)"],"metadata":{"id":"Fin_rx-rRmyI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_, teloader = prepare_test_data(args)\n","_, trloader = prepare_train_data(args)\n","\n","# load from checkpoint to resume training\n","checkpoint_dir = 'results/cifar10_tensor_layer2_gn_expand/ckpt.pth'\n","ckpt = torch.load(checkpoint_dir)\n","net.load_state_dict(ckpt['net'], strict=False)\n","head.load_state_dict(ckpt['head'], strict=False)\n","print('resume training from checkpoint ' + str(checkpoint_dir))\n","\n","# create (50k x rank) tensors, store on cpu\n","u_train_net = []\n","u_test_net = []\n","u_train_head = []\n","u_test_head = []\n","\n","for param_name, param in net.named_parameters():\n","    if 'weight.weights' in param_name:\n","        u_train_net.append(torch.ones((len(trloader.dataset), len(param)), pin_memory=True))\n","        u_test_net.append(torch.ones((len(teloader.dataset), len(param)), pin_memory=True))\n","\n","for param_name, param in head.named_parameters():\n","    if 'weight.weights' in param_name:\n","        u_train_head.append(torch.ones((len(trloader.dataset), len(param)), pin_memory=True))\n","        u_test_head.append(torch.ones((len(teloader.dataset), len(param)), pin_memory=True))\n","\n","parameters = list(net.parameters()) + list(head.parameters())\n","optimizer = optim.SGD(parameters, lr=args.lr, momentum=0.9, weight_decay=5e-4)\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(\n","    optimizer, [args.milestone_1, args.milestone_2], gamma=0.1, last_epoch=-1)\n","criterion = nn.CrossEntropyLoss().cuda()\n","\n","print(\"net's state_dict:\")\n","for param_tensor in net.state_dict():\n","    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n","\n","print(\"ssh's state_dict:\")\n","for param_tensor in ssh.state_dict():\n","    print(param_tensor, \"\\t\", ssh.state_dict()[param_tensor].size())\n","\n","all_err_cls = []\n","all_err_ssh = []\n","all_loss = []\n","all_loss_ssh = []\n","print('Running...')\n","print('Error (%)\\t\\ttest\\t\\tself-supervised\\t\\tloss_last_batch\\t\\tloss_ssh_last_batch')\n","for epoch in range(1, args.nepoch + 1):\n","    net.train()\n","    ssh.train()\n","\n","    for batch_idx, (inputs, labels, data_idx) in enumerate(trloader):\n","      if batch_idx==\n","        optimizer.zero_grad()\n","        inputs_cls, labels_cls = inputs.cuda(), labels.cuda()\n","\n","        u_train_net_data = [u_train_net[ll][data_idx, :].cuda() for ll in range(len(u_train_net))]\n","        u_train_head_data = [u_train_head[ll][data_idx, :].cuda() for ll in range(len(u_train_head))]\n","        load_trainable_weights(net, u_train_net_data)\n","        load_trainable_weights(head, u_train_head_data)\n","\n","        outputs_cls = net(inputs_cls, adapt=True)\n","        loss = criterion(outputs_cls, labels_cls)\n","\n","        if args.shared is not None:\n","            inputs_ssh, labels_ssh = rotate_batch(inputs, args.rotation_type)\n","            inputs_ssh, labels_ssh = inputs_ssh.cuda(), labels_ssh.cuda()\n","            outputs_ssh = ssh(inputs_ssh, adapt=True)\n","            loss_ssh = criterion(outputs_ssh, labels_ssh)\n","            loss += loss_ssh\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        u_train_net_data = save_trainable_weights(net)\n","        u_train_head_data = save_trainable_weights(head)\n","\n","        for ll in range(len(u_train_net_data)):\n","            u_train_net[ll][data_idx, :] = u_train_net_data[ll].clone().detach().cpu()\n","        for ll in range(len(u_train_head_data)):\n","            u_train_head[ll][data_idx, :] = u_train_head_data[ll].clone().detach().cpu()\n","\n","    err_cls = test(teloader, net, adapt=True)[0]\n","    err_ssh = 0 if args.shared is None else test(teloader, ssh, sslabel='expand', adapt=True)[0]\n","    all_err_cls.append(err_cls)\n","    all_err_ssh.append(err_ssh)\n","    all_loss.append(loss)\n","    all_loss_ssh.append(loss_ssh)\n","    scheduler.step()\n","\n","    print(('Epoch %d/%d:' % (epoch, args.nepoch)).ljust(24) +\n","          '%.2f\\t\\t%.2f\\t\\t%.2f\\t\\t%.2f' % (err_cls * 100, err_ssh * 100, loss, loss_ssh))\n","    torch.save((all_err_cls, all_err_ssh), args.outf + '/loss.pth')\n","    torch.save((all_loss, all_loss_ssh), args.outf + '/train_loss_last_batch.pth')\n","    plot_epochs(all_err_cls, all_err_ssh, args.outf + '/loss.pdf')\n","\n","    if epoch % 5 == 0:\n","        checkpoint_dir = args.outf + '/checkpoint' + str(epoch) + '.pt'\n","        print(checkpoint_dir)\n","        checkpoint = {\n","            'epoch': epoch + 1,\n","            'net': net.state_dict(),\n","            'head': head.state_dict(),\n","            'optimizer': optimizer.state_dict()\n","        }\n","        save_ckp(checkpoint, checkpoint_dir)\n","\n","state = {'err_cls': err_cls, 'err_ssh': err_ssh,\n","         'net': net.state_dict(), 'head': head.state_dict(),\n","         'optimizer': optimizer.state_dict()}\n","torch.save(state, args.outf + '/ckpt.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hp06vlXUK9oz","executionInfo":{"status":"error","timestamp":1647511967191,"user_tz":420,"elapsed":269425,"user":{"displayName":"Ziqing Zhong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09288499055193360161"}},"outputId":"4fc4ed0a-cd5e-4dd0-8c67-535b5b1a8cbd"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["resume training from checkpoint results/cifar10_tensor_layer2_gn_expand/ckpt.pth\n","net's state_dict:\n","conv1.adaptive_weights_preconv_trainable \t torch.Size([128, 19])\n","conv1.conv1.weight.weights \t torch.Size([19])\n","conv1.conv1.weight.factors.factor_0 \t torch.Size([16, 19])\n","conv1.conv1.weight.factors.factor_1 \t torch.Size([3, 19])\n","conv1.conv1.weight.factors.factor_2 \t torch.Size([3, 19])\n","conv1.conv1.weight.factors.factor_3 \t torch.Size([3, 19])\n","layer1.0.adaptive_weights_conv1_trainable \t torch.Size([128, 67])\n","layer1.0.adaptive_weights_conv2_trainable \t torch.Size([128, 67])\n","layer1.0.bn1.weight \t torch.Size([16])\n","layer1.0.bn1.bias \t torch.Size([16])\n","layer1.0.conv1.weight.weights \t torch.Size([67])\n","layer1.0.conv1.weight.factors.factor_0 \t torch.Size([16, 67])\n","layer1.0.conv1.weight.factors.factor_1 \t torch.Size([16, 67])\n","layer1.0.conv1.weight.factors.factor_2 \t torch.Size([3, 67])\n","layer1.0.conv1.weight.factors.factor_3 \t torch.Size([3, 67])\n","layer1.0.bn2.weight \t torch.Size([16])\n","layer1.0.bn2.bias \t torch.Size([16])\n","layer1.0.conv2.weight.weights \t torch.Size([67])\n","layer1.0.conv2.weight.factors.factor_0 \t torch.Size([16, 67])\n","layer1.0.conv2.weight.factors.factor_1 \t torch.Size([16, 67])\n","layer1.0.conv2.weight.factors.factor_2 \t torch.Size([3, 67])\n","layer1.0.conv2.weight.factors.factor_3 \t torch.Size([3, 67])\n","layer1.1.adaptive_weights_conv1_trainable \t torch.Size([128, 67])\n","layer1.1.adaptive_weights_conv2_trainable \t torch.Size([128, 67])\n","layer1.1.bn1.weight \t torch.Size([16])\n","layer1.1.bn1.bias \t torch.Size([16])\n","layer1.1.conv1.weight.weights \t torch.Size([67])\n","layer1.1.conv1.weight.factors.factor_0 \t torch.Size([16, 67])\n","layer1.1.conv1.weight.factors.factor_1 \t torch.Size([16, 67])\n","layer1.1.conv1.weight.factors.factor_2 \t torch.Size([3, 67])\n","layer1.1.conv1.weight.factors.factor_3 \t torch.Size([3, 67])\n","layer1.1.bn2.weight \t torch.Size([16])\n","layer1.1.bn2.bias \t torch.Size([16])\n","layer1.1.conv2.weight.weights \t torch.Size([67])\n","layer1.1.conv2.weight.factors.factor_0 \t torch.Size([16, 67])\n","layer1.1.conv2.weight.factors.factor_1 \t torch.Size([16, 67])\n","layer1.1.conv2.weight.factors.factor_2 \t torch.Size([3, 67])\n","layer1.1.conv2.weight.factors.factor_3 \t torch.Size([3, 67])\n","layer1.2.adaptive_weights_conv1_trainable \t torch.Size([128, 67])\n","layer1.2.adaptive_weights_conv2_trainable \t torch.Size([128, 67])\n","layer1.2.bn1.weight \t torch.Size([16])\n","layer1.2.bn1.bias \t torch.Size([16])\n","layer1.2.conv1.weight.weights \t torch.Size([67])\n","layer1.2.conv1.weight.factors.factor_0 \t torch.Size([16, 67])\n","layer1.2.conv1.weight.factors.factor_1 \t torch.Size([16, 67])\n","layer1.2.conv1.weight.factors.factor_2 \t torch.Size([3, 67])\n","layer1.2.conv1.weight.factors.factor_3 \t torch.Size([3, 67])\n","layer1.2.bn2.weight \t torch.Size([16])\n","layer1.2.bn2.bias \t torch.Size([16])\n","layer1.2.conv2.weight.weights \t torch.Size([67])\n","layer1.2.conv2.weight.factors.factor_0 \t torch.Size([16, 67])\n","layer1.2.conv2.weight.factors.factor_1 \t torch.Size([16, 67])\n","layer1.2.conv2.weight.factors.factor_2 \t torch.Size([3, 67])\n","layer1.2.conv2.weight.factors.factor_3 \t torch.Size([3, 67])\n","layer1.3.adaptive_weights_conv1_trainable \t torch.Size([128, 67])\n","layer1.3.adaptive_weights_conv2_trainable \t torch.Size([128, 67])\n","layer1.3.bn1.weight \t torch.Size([16])\n","layer1.3.bn1.bias \t torch.Size([16])\n","layer1.3.conv1.weight.weights \t torch.Size([67])\n","layer1.3.conv1.weight.factors.factor_0 \t torch.Size([16, 67])\n","layer1.3.conv1.weight.factors.factor_1 \t torch.Size([16, 67])\n","layer1.3.conv1.weight.factors.factor_2 \t torch.Size([3, 67])\n","layer1.3.conv1.weight.factors.factor_3 \t torch.Size([3, 67])\n","layer1.3.bn2.weight \t torch.Size([16])\n","layer1.3.bn2.bias \t torch.Size([16])\n","layer1.3.conv2.weight.weights \t torch.Size([67])\n","layer1.3.conv2.weight.factors.factor_0 \t torch.Size([16, 67])\n","layer1.3.conv2.weight.factors.factor_1 \t torch.Size([16, 67])\n","layer1.3.conv2.weight.factors.factor_2 \t torch.Size([3, 67])\n","layer1.3.conv2.weight.factors.factor_3 \t torch.Size([3, 67])\n","layer2.0.adaptive_weights_conv1_trainable \t torch.Size([128, 94])\n","layer2.0.adaptive_weights_conv2_trainable \t torch.Size([128, 145])\n","layer2.0.bn1.weight \t torch.Size([16])\n","layer2.0.bn1.bias \t torch.Size([16])\n","layer2.0.conv1.weight.weights \t torch.Size([94])\n","layer2.0.conv1.weight.factors.factor_0 \t torch.Size([32, 94])\n","layer2.0.conv1.weight.factors.factor_1 \t torch.Size([16, 94])\n","layer2.0.conv1.weight.factors.factor_2 \t torch.Size([3, 94])\n","layer2.0.conv1.weight.factors.factor_3 \t torch.Size([3, 94])\n","layer2.0.bn2.weight \t torch.Size([32])\n","layer2.0.bn2.bias \t torch.Size([32])\n","layer2.0.conv2.weight.weights \t torch.Size([145])\n","layer2.0.conv2.weight.factors.factor_0 \t torch.Size([32, 145])\n","layer2.0.conv2.weight.factors.factor_1 \t torch.Size([32, 145])\n","layer2.0.conv2.weight.factors.factor_2 \t torch.Size([3, 145])\n","layer2.0.conv2.weight.factors.factor_3 \t torch.Size([3, 145])\n","layer2.1.adaptive_weights_conv1_trainable \t torch.Size([128, 145])\n","layer2.1.adaptive_weights_conv2_trainable \t torch.Size([128, 145])\n","layer2.1.bn1.weight \t torch.Size([32])\n","layer2.1.bn1.bias \t torch.Size([32])\n","layer2.1.conv1.weight.weights \t torch.Size([145])\n","layer2.1.conv1.weight.factors.factor_0 \t torch.Size([32, 145])\n","layer2.1.conv1.weight.factors.factor_1 \t torch.Size([32, 145])\n","layer2.1.conv1.weight.factors.factor_2 \t torch.Size([3, 145])\n","layer2.1.conv1.weight.factors.factor_3 \t torch.Size([3, 145])\n","layer2.1.bn2.weight \t torch.Size([32])\n","layer2.1.bn2.bias \t torch.Size([32])\n","layer2.1.conv2.weight.weights \t torch.Size([145])\n","layer2.1.conv2.weight.factors.factor_0 \t torch.Size([32, 145])\n","layer2.1.conv2.weight.factors.factor_1 \t torch.Size([32, 145])\n","layer2.1.conv2.weight.factors.factor_2 \t torch.Size([3, 145])\n","layer2.1.conv2.weight.factors.factor_3 \t torch.Size([3, 145])\n","layer2.2.adaptive_weights_conv1_trainable \t torch.Size([128, 145])\n","layer2.2.adaptive_weights_conv2_trainable \t torch.Size([128, 145])\n","layer2.2.bn1.weight \t torch.Size([32])\n","layer2.2.bn1.bias \t torch.Size([32])\n","layer2.2.conv1.weight.weights \t torch.Size([145])\n","layer2.2.conv1.weight.factors.factor_0 \t torch.Size([32, 145])\n","layer2.2.conv1.weight.factors.factor_1 \t torch.Size([32, 145])\n","layer2.2.conv1.weight.factors.factor_2 \t torch.Size([3, 145])\n","layer2.2.conv1.weight.factors.factor_3 \t torch.Size([3, 145])\n","layer2.2.bn2.weight \t torch.Size([32])\n","layer2.2.bn2.bias \t torch.Size([32])\n","layer2.2.conv2.weight.weights \t torch.Size([145])\n","layer2.2.conv2.weight.factors.factor_0 \t torch.Size([32, 145])\n","layer2.2.conv2.weight.factors.factor_1 \t torch.Size([32, 145])\n","layer2.2.conv2.weight.factors.factor_2 \t torch.Size([3, 145])\n","layer2.2.conv2.weight.factors.factor_3 \t torch.Size([3, 145])\n","layer2.3.adaptive_weights_conv1_trainable \t torch.Size([128, 145])\n","layer2.3.adaptive_weights_conv2_trainable \t torch.Size([128, 145])\n","layer2.3.bn1.weight \t torch.Size([32])\n","layer2.3.bn1.bias \t torch.Size([32])\n","layer2.3.conv1.weight.weights \t torch.Size([145])\n","layer2.3.conv1.weight.factors.factor_0 \t torch.Size([32, 145])\n","layer2.3.conv1.weight.factors.factor_1 \t torch.Size([32, 145])\n","layer2.3.conv1.weight.factors.factor_2 \t torch.Size([3, 145])\n","layer2.3.conv1.weight.factors.factor_3 \t torch.Size([3, 145])\n","layer2.3.bn2.weight \t torch.Size([32])\n","layer2.3.bn2.bias \t torch.Size([32])\n","layer2.3.conv2.weight.weights \t torch.Size([145])\n","layer2.3.conv2.weight.factors.factor_0 \t torch.Size([32, 145])\n","layer2.3.conv2.weight.factors.factor_1 \t torch.Size([32, 145])\n","layer2.3.conv2.weight.factors.factor_2 \t torch.Size([3, 145])\n","layer2.3.conv2.weight.factors.factor_3 \t torch.Size([3, 145])\n","layer3.0.adaptive_weights_conv1_trainable \t torch.Size([128, 199])\n","layer3.0.adaptive_weights_conv2_trainable \t torch.Size([128, 303])\n","layer3.0.bn1.weight \t torch.Size([32])\n","layer3.0.bn1.bias \t torch.Size([32])\n","layer3.0.conv1.weight.weights \t torch.Size([199])\n","layer3.0.conv1.weight.factors.factor_0 \t torch.Size([64, 199])\n","layer3.0.conv1.weight.factors.factor_1 \t torch.Size([32, 199])\n","layer3.0.conv1.weight.factors.factor_2 \t torch.Size([3, 199])\n","layer3.0.conv1.weight.factors.factor_3 \t torch.Size([3, 199])\n","layer3.0.bn2.weight \t torch.Size([64])\n","layer3.0.bn2.bias \t torch.Size([64])\n","layer3.0.conv2.weight.weights \t torch.Size([303])\n","layer3.0.conv2.weight.factors.factor_0 \t torch.Size([64, 303])\n","layer3.0.conv2.weight.factors.factor_1 \t torch.Size([64, 303])\n","layer3.0.conv2.weight.factors.factor_2 \t torch.Size([3, 303])\n","layer3.0.conv2.weight.factors.factor_3 \t torch.Size([3, 303])\n","layer3.1.adaptive_weights_conv1_trainable \t torch.Size([128, 303])\n","layer3.1.adaptive_weights_conv2_trainable \t torch.Size([128, 303])\n","layer3.1.bn1.weight \t torch.Size([64])\n","layer3.1.bn1.bias \t torch.Size([64])\n","layer3.1.conv1.weight.weights \t torch.Size([303])\n","layer3.1.conv1.weight.factors.factor_0 \t torch.Size([64, 303])\n","layer3.1.conv1.weight.factors.factor_1 \t torch.Size([64, 303])\n","layer3.1.conv1.weight.factors.factor_2 \t torch.Size([3, 303])\n","layer3.1.conv1.weight.factors.factor_3 \t torch.Size([3, 303])\n","layer3.1.bn2.weight \t torch.Size([64])\n","layer3.1.bn2.bias \t torch.Size([64])\n","layer3.1.conv2.weight.weights \t torch.Size([303])\n","layer3.1.conv2.weight.factors.factor_0 \t torch.Size([64, 303])\n","layer3.1.conv2.weight.factors.factor_1 \t torch.Size([64, 303])\n","layer3.1.conv2.weight.factors.factor_2 \t torch.Size([3, 303])\n","layer3.1.conv2.weight.factors.factor_3 \t torch.Size([3, 303])\n","layer3.2.adaptive_weights_conv1_trainable \t torch.Size([128, 303])\n","layer3.2.adaptive_weights_conv2_trainable \t torch.Size([128, 303])\n","layer3.2.bn1.weight \t torch.Size([64])\n","layer3.2.bn1.bias \t torch.Size([64])\n","layer3.2.conv1.weight.weights \t torch.Size([303])\n","layer3.2.conv1.weight.factors.factor_0 \t torch.Size([64, 303])\n","layer3.2.conv1.weight.factors.factor_1 \t torch.Size([64, 303])\n","layer3.2.conv1.weight.factors.factor_2 \t torch.Size([3, 303])\n","layer3.2.conv1.weight.factors.factor_3 \t torch.Size([3, 303])\n","layer3.2.bn2.weight \t torch.Size([64])\n","layer3.2.bn2.bias \t torch.Size([64])\n","layer3.2.conv2.weight.weights \t torch.Size([303])\n","layer3.2.conv2.weight.factors.factor_0 \t torch.Size([64, 303])\n","layer3.2.conv2.weight.factors.factor_1 \t torch.Size([64, 303])\n","layer3.2.conv2.weight.factors.factor_2 \t torch.Size([3, 303])\n","layer3.2.conv2.weight.factors.factor_3 \t torch.Size([3, 303])\n","layer3.3.adaptive_weights_conv1_trainable \t torch.Size([128, 303])\n","layer3.3.adaptive_weights_conv2_trainable \t torch.Size([128, 303])\n","layer3.3.bn1.weight \t torch.Size([64])\n","layer3.3.bn1.bias \t torch.Size([64])\n","layer3.3.conv1.weight.weights \t torch.Size([303])\n","layer3.3.conv1.weight.factors.factor_0 \t torch.Size([64, 303])\n","layer3.3.conv1.weight.factors.factor_1 \t torch.Size([64, 303])\n","layer3.3.conv1.weight.factors.factor_2 \t torch.Size([3, 303])\n","layer3.3.conv1.weight.factors.factor_3 \t torch.Size([3, 303])\n","layer3.3.bn2.weight \t torch.Size([64])\n","layer3.3.bn2.bias \t torch.Size([64])\n","layer3.3.conv2.weight.weights \t torch.Size([303])\n","layer3.3.conv2.weight.factors.factor_0 \t torch.Size([64, 303])\n","layer3.3.conv2.weight.factors.factor_1 \t torch.Size([64, 303])\n","layer3.3.conv2.weight.factors.factor_2 \t torch.Size([3, 303])\n","layer3.3.conv2.weight.factors.factor_3 \t torch.Size([3, 303])\n","bn.weight \t torch.Size([64])\n","bn.bias \t torch.Size([64])\n","fc.weight \t torch.Size([10, 64])\n","fc.bias \t torch.Size([10])\n","ssh's state_dict:\n","ext.0.adaptive_weights_preconv_trainable \t torch.Size([128, 19])\n","ext.0.conv1.weight.weights \t torch.Size([19])\n","ext.0.conv1.weight.factors.factor_0 \t torch.Size([16, 19])\n","ext.0.conv1.weight.factors.factor_1 \t torch.Size([3, 19])\n","ext.0.conv1.weight.factors.factor_2 \t torch.Size([3, 19])\n","ext.0.conv1.weight.factors.factor_3 \t torch.Size([3, 19])\n","ext.1.0.adaptive_weights_conv1_trainable \t torch.Size([128, 67])\n","ext.1.0.adaptive_weights_conv2_trainable \t torch.Size([128, 67])\n","ext.1.0.bn1.weight \t torch.Size([16])\n","ext.1.0.bn1.bias \t torch.Size([16])\n","ext.1.0.conv1.weight.weights \t torch.Size([67])\n","ext.1.0.conv1.weight.factors.factor_0 \t torch.Size([16, 67])\n","ext.1.0.conv1.weight.factors.factor_1 \t torch.Size([16, 67])\n","ext.1.0.conv1.weight.factors.factor_2 \t torch.Size([3, 67])\n","ext.1.0.conv1.weight.factors.factor_3 \t torch.Size([3, 67])\n","ext.1.0.bn2.weight \t torch.Size([16])\n","ext.1.0.bn2.bias \t torch.Size([16])\n","ext.1.0.conv2.weight.weights \t torch.Size([67])\n","ext.1.0.conv2.weight.factors.factor_0 \t torch.Size([16, 67])\n","ext.1.0.conv2.weight.factors.factor_1 \t torch.Size([16, 67])\n","ext.1.0.conv2.weight.factors.factor_2 \t torch.Size([3, 67])\n","ext.1.0.conv2.weight.factors.factor_3 \t torch.Size([3, 67])\n","ext.1.1.adaptive_weights_conv1_trainable \t torch.Size([128, 67])\n","ext.1.1.adaptive_weights_conv2_trainable \t torch.Size([128, 67])\n","ext.1.1.bn1.weight \t torch.Size([16])\n","ext.1.1.bn1.bias \t torch.Size([16])\n","ext.1.1.conv1.weight.weights \t torch.Size([67])\n","ext.1.1.conv1.weight.factors.factor_0 \t torch.Size([16, 67])\n","ext.1.1.conv1.weight.factors.factor_1 \t torch.Size([16, 67])\n","ext.1.1.conv1.weight.factors.factor_2 \t torch.Size([3, 67])\n","ext.1.1.conv1.weight.factors.factor_3 \t torch.Size([3, 67])\n","ext.1.1.bn2.weight \t torch.Size([16])\n","ext.1.1.bn2.bias \t torch.Size([16])\n","ext.1.1.conv2.weight.weights \t torch.Size([67])\n","ext.1.1.conv2.weight.factors.factor_0 \t torch.Size([16, 67])\n","ext.1.1.conv2.weight.factors.factor_1 \t torch.Size([16, 67])\n","ext.1.1.conv2.weight.factors.factor_2 \t torch.Size([3, 67])\n","ext.1.1.conv2.weight.factors.factor_3 \t torch.Size([3, 67])\n","ext.1.2.adaptive_weights_conv1_trainable \t torch.Size([128, 67])\n","ext.1.2.adaptive_weights_conv2_trainable \t torch.Size([128, 67])\n","ext.1.2.bn1.weight \t torch.Size([16])\n","ext.1.2.bn1.bias \t torch.Size([16])\n","ext.1.2.conv1.weight.weights \t torch.Size([67])\n","ext.1.2.conv1.weight.factors.factor_0 \t torch.Size([16, 67])\n","ext.1.2.conv1.weight.factors.factor_1 \t torch.Size([16, 67])\n","ext.1.2.conv1.weight.factors.factor_2 \t torch.Size([3, 67])\n","ext.1.2.conv1.weight.factors.factor_3 \t torch.Size([3, 67])\n","ext.1.2.bn2.weight \t torch.Size([16])\n","ext.1.2.bn2.bias \t torch.Size([16])\n","ext.1.2.conv2.weight.weights \t torch.Size([67])\n","ext.1.2.conv2.weight.factors.factor_0 \t torch.Size([16, 67])\n","ext.1.2.conv2.weight.factors.factor_1 \t torch.Size([16, 67])\n","ext.1.2.conv2.weight.factors.factor_2 \t torch.Size([3, 67])\n","ext.1.2.conv2.weight.factors.factor_3 \t torch.Size([3, 67])\n","ext.1.3.adaptive_weights_conv1_trainable \t torch.Size([128, 67])\n","ext.1.3.adaptive_weights_conv2_trainable \t torch.Size([128, 67])\n","ext.1.3.bn1.weight \t torch.Size([16])\n","ext.1.3.bn1.bias \t torch.Size([16])\n","ext.1.3.conv1.weight.weights \t torch.Size([67])\n","ext.1.3.conv1.weight.factors.factor_0 \t torch.Size([16, 67])\n","ext.1.3.conv1.weight.factors.factor_1 \t torch.Size([16, 67])\n","ext.1.3.conv1.weight.factors.factor_2 \t torch.Size([3, 67])\n","ext.1.3.conv1.weight.factors.factor_3 \t torch.Size([3, 67])\n","ext.1.3.bn2.weight \t torch.Size([16])\n","ext.1.3.bn2.bias \t torch.Size([16])\n","ext.1.3.conv2.weight.weights \t torch.Size([67])\n","ext.1.3.conv2.weight.factors.factor_0 \t torch.Size([16, 67])\n","ext.1.3.conv2.weight.factors.factor_1 \t torch.Size([16, 67])\n","ext.1.3.conv2.weight.factors.factor_2 \t torch.Size([3, 67])\n","ext.1.3.conv2.weight.factors.factor_3 \t torch.Size([3, 67])\n","ext.2.0.adaptive_weights_conv1_trainable \t torch.Size([128, 94])\n","ext.2.0.adaptive_weights_conv2_trainable \t torch.Size([128, 145])\n","ext.2.0.bn1.weight \t torch.Size([16])\n","ext.2.0.bn1.bias \t torch.Size([16])\n","ext.2.0.conv1.weight.weights \t torch.Size([94])\n","ext.2.0.conv1.weight.factors.factor_0 \t torch.Size([32, 94])\n","ext.2.0.conv1.weight.factors.factor_1 \t torch.Size([16, 94])\n","ext.2.0.conv1.weight.factors.factor_2 \t torch.Size([3, 94])\n","ext.2.0.conv1.weight.factors.factor_3 \t torch.Size([3, 94])\n","ext.2.0.bn2.weight \t torch.Size([32])\n","ext.2.0.bn2.bias \t torch.Size([32])\n","ext.2.0.conv2.weight.weights \t torch.Size([145])\n","ext.2.0.conv2.weight.factors.factor_0 \t torch.Size([32, 145])\n","ext.2.0.conv2.weight.factors.factor_1 \t torch.Size([32, 145])\n","ext.2.0.conv2.weight.factors.factor_2 \t torch.Size([3, 145])\n","ext.2.0.conv2.weight.factors.factor_3 \t torch.Size([3, 145])\n","ext.2.1.adaptive_weights_conv1_trainable \t torch.Size([128, 145])\n","ext.2.1.adaptive_weights_conv2_trainable \t torch.Size([128, 145])\n","ext.2.1.bn1.weight \t torch.Size([32])\n","ext.2.1.bn1.bias \t torch.Size([32])\n","ext.2.1.conv1.weight.weights \t torch.Size([145])\n","ext.2.1.conv1.weight.factors.factor_0 \t torch.Size([32, 145])\n","ext.2.1.conv1.weight.factors.factor_1 \t torch.Size([32, 145])\n","ext.2.1.conv1.weight.factors.factor_2 \t torch.Size([3, 145])\n","ext.2.1.conv1.weight.factors.factor_3 \t torch.Size([3, 145])\n","ext.2.1.bn2.weight \t torch.Size([32])\n","ext.2.1.bn2.bias \t torch.Size([32])\n","ext.2.1.conv2.weight.weights \t torch.Size([145])\n","ext.2.1.conv2.weight.factors.factor_0 \t torch.Size([32, 145])\n","ext.2.1.conv2.weight.factors.factor_1 \t torch.Size([32, 145])\n","ext.2.1.conv2.weight.factors.factor_2 \t torch.Size([3, 145])\n","ext.2.1.conv2.weight.factors.factor_3 \t torch.Size([3, 145])\n","ext.2.2.adaptive_weights_conv1_trainable \t torch.Size([128, 145])\n","ext.2.2.adaptive_weights_conv2_trainable \t torch.Size([128, 145])\n","ext.2.2.bn1.weight \t torch.Size([32])\n","ext.2.2.bn1.bias \t torch.Size([32])\n","ext.2.2.conv1.weight.weights \t torch.Size([145])\n","ext.2.2.conv1.weight.factors.factor_0 \t torch.Size([32, 145])\n","ext.2.2.conv1.weight.factors.factor_1 \t torch.Size([32, 145])\n","ext.2.2.conv1.weight.factors.factor_2 \t torch.Size([3, 145])\n","ext.2.2.conv1.weight.factors.factor_3 \t torch.Size([3, 145])\n","ext.2.2.bn2.weight \t torch.Size([32])\n","ext.2.2.bn2.bias \t torch.Size([32])\n","ext.2.2.conv2.weight.weights \t torch.Size([145])\n","ext.2.2.conv2.weight.factors.factor_0 \t torch.Size([32, 145])\n","ext.2.2.conv2.weight.factors.factor_1 \t torch.Size([32, 145])\n","ext.2.2.conv2.weight.factors.factor_2 \t torch.Size([3, 145])\n","ext.2.2.conv2.weight.factors.factor_3 \t torch.Size([3, 145])\n","ext.2.3.adaptive_weights_conv1_trainable \t torch.Size([128, 145])\n","ext.2.3.adaptive_weights_conv2_trainable \t torch.Size([128, 145])\n","ext.2.3.bn1.weight \t torch.Size([32])\n","ext.2.3.bn1.bias \t torch.Size([32])\n","ext.2.3.conv1.weight.weights \t torch.Size([145])\n","ext.2.3.conv1.weight.factors.factor_0 \t torch.Size([32, 145])\n","ext.2.3.conv1.weight.factors.factor_1 \t torch.Size([32, 145])\n","ext.2.3.conv1.weight.factors.factor_2 \t torch.Size([3, 145])\n","ext.2.3.conv1.weight.factors.factor_3 \t torch.Size([3, 145])\n","ext.2.3.bn2.weight \t torch.Size([32])\n","ext.2.3.bn2.bias \t torch.Size([32])\n","ext.2.3.conv2.weight.weights \t torch.Size([145])\n","ext.2.3.conv2.weight.factors.factor_0 \t torch.Size([32, 145])\n","ext.2.3.conv2.weight.factors.factor_1 \t torch.Size([32, 145])\n","ext.2.3.conv2.weight.factors.factor_2 \t torch.Size([3, 145])\n","ext.2.3.conv2.weight.factors.factor_3 \t torch.Size([3, 145])\n","head.layer3.0.adaptive_weights_conv1_trainable \t torch.Size([128, 199])\n","head.layer3.0.adaptive_weights_conv2_trainable \t torch.Size([128, 303])\n","head.layer3.0.bn1.weight \t torch.Size([32])\n","head.layer3.0.bn1.bias \t torch.Size([32])\n","head.layer3.0.bn1.running_mean \t torch.Size([32])\n","head.layer3.0.bn1.running_var \t torch.Size([32])\n","head.layer3.0.bn1.num_batches_tracked \t torch.Size([])\n","head.layer3.0.conv1.weight.weights \t torch.Size([199])\n","head.layer3.0.conv1.weight.factors.factor_0 \t torch.Size([64, 199])\n","head.layer3.0.conv1.weight.factors.factor_1 \t torch.Size([32, 199])\n","head.layer3.0.conv1.weight.factors.factor_2 \t torch.Size([3, 199])\n","head.layer3.0.conv1.weight.factors.factor_3 \t torch.Size([3, 199])\n","head.layer3.0.bn2.weight \t torch.Size([64])\n","head.layer3.0.bn2.bias \t torch.Size([64])\n","head.layer3.0.bn2.running_mean \t torch.Size([64])\n","head.layer3.0.bn2.running_var \t torch.Size([64])\n","head.layer3.0.bn2.num_batches_tracked \t torch.Size([])\n","head.layer3.0.conv2.weight.weights \t torch.Size([303])\n","head.layer3.0.conv2.weight.factors.factor_0 \t torch.Size([64, 303])\n","head.layer3.0.conv2.weight.factors.factor_1 \t torch.Size([64, 303])\n","head.layer3.0.conv2.weight.factors.factor_2 \t torch.Size([3, 303])\n","head.layer3.0.conv2.weight.factors.factor_3 \t torch.Size([3, 303])\n","head.layer3.1.adaptive_weights_conv1_trainable \t torch.Size([128, 303])\n","head.layer3.1.adaptive_weights_conv2_trainable \t torch.Size([128, 303])\n","head.layer3.1.bn1.weight \t torch.Size([64])\n","head.layer3.1.bn1.bias \t torch.Size([64])\n","head.layer3.1.bn1.running_mean \t torch.Size([64])\n","head.layer3.1.bn1.running_var \t torch.Size([64])\n","head.layer3.1.bn1.num_batches_tracked \t torch.Size([])\n","head.layer3.1.conv1.weight.weights \t torch.Size([303])\n","head.layer3.1.conv1.weight.factors.factor_0 \t torch.Size([64, 303])\n","head.layer3.1.conv1.weight.factors.factor_1 \t torch.Size([64, 303])\n","head.layer3.1.conv1.weight.factors.factor_2 \t torch.Size([3, 303])\n","head.layer3.1.conv1.weight.factors.factor_3 \t torch.Size([3, 303])\n","head.layer3.1.bn2.weight \t torch.Size([64])\n","head.layer3.1.bn2.bias \t torch.Size([64])\n","head.layer3.1.bn2.running_mean \t torch.Size([64])\n","head.layer3.1.bn2.running_var \t torch.Size([64])\n","head.layer3.1.bn2.num_batches_tracked \t torch.Size([])\n","head.layer3.1.conv2.weight.weights \t torch.Size([303])\n","head.layer3.1.conv2.weight.factors.factor_0 \t torch.Size([64, 303])\n","head.layer3.1.conv2.weight.factors.factor_1 \t torch.Size([64, 303])\n","head.layer3.1.conv2.weight.factors.factor_2 \t torch.Size([3, 303])\n","head.layer3.1.conv2.weight.factors.factor_3 \t torch.Size([3, 303])\n","head.layer3.2.adaptive_weights_conv1_trainable \t torch.Size([128, 303])\n","head.layer3.2.adaptive_weights_conv2_trainable \t torch.Size([128, 303])\n","head.layer3.2.bn1.weight \t torch.Size([64])\n","head.layer3.2.bn1.bias \t torch.Size([64])\n","head.layer3.2.bn1.running_mean \t torch.Size([64])\n","head.layer3.2.bn1.running_var \t torch.Size([64])\n","head.layer3.2.bn1.num_batches_tracked \t torch.Size([])\n","head.layer3.2.conv1.weight.weights \t torch.Size([303])\n","head.layer3.2.conv1.weight.factors.factor_0 \t torch.Size([64, 303])\n","head.layer3.2.conv1.weight.factors.factor_1 \t torch.Size([64, 303])\n","head.layer3.2.conv1.weight.factors.factor_2 \t torch.Size([3, 303])\n","head.layer3.2.conv1.weight.factors.factor_3 \t torch.Size([3, 303])\n","head.layer3.2.bn2.weight \t torch.Size([64])\n","head.layer3.2.bn2.bias \t torch.Size([64])\n","head.layer3.2.bn2.running_mean \t torch.Size([64])\n","head.layer3.2.bn2.running_var \t torch.Size([64])\n","head.layer3.2.bn2.num_batches_tracked \t torch.Size([])\n","head.layer3.2.conv2.weight.weights \t torch.Size([303])\n","head.layer3.2.conv2.weight.factors.factor_0 \t torch.Size([64, 303])\n","head.layer3.2.conv2.weight.factors.factor_1 \t torch.Size([64, 303])\n","head.layer3.2.conv2.weight.factors.factor_2 \t torch.Size([3, 303])\n","head.layer3.2.conv2.weight.factors.factor_3 \t torch.Size([3, 303])\n","head.layer3.3.adaptive_weights_conv1_trainable \t torch.Size([128, 303])\n","head.layer3.3.adaptive_weights_conv2_trainable \t torch.Size([128, 303])\n","head.layer3.3.bn1.weight \t torch.Size([64])\n","head.layer3.3.bn1.bias \t torch.Size([64])\n","head.layer3.3.bn1.running_mean \t torch.Size([64])\n","head.layer3.3.bn1.running_var \t torch.Size([64])\n","head.layer3.3.bn1.num_batches_tracked \t torch.Size([])\n","head.layer3.3.conv1.weight.weights \t torch.Size([303])\n","head.layer3.3.conv1.weight.factors.factor_0 \t torch.Size([64, 303])\n","head.layer3.3.conv1.weight.factors.factor_1 \t torch.Size([64, 303])\n","head.layer3.3.conv1.weight.factors.factor_2 \t torch.Size([3, 303])\n","head.layer3.3.conv1.weight.factors.factor_3 \t torch.Size([3, 303])\n","head.layer3.3.bn2.weight \t torch.Size([64])\n","head.layer3.3.bn2.bias \t torch.Size([64])\n","head.layer3.3.bn2.running_mean \t torch.Size([64])\n","head.layer3.3.bn2.running_var \t torch.Size([64])\n","head.layer3.3.bn2.num_batches_tracked \t torch.Size([])\n","head.layer3.3.conv2.weight.weights \t torch.Size([303])\n","head.layer3.3.conv2.weight.factors.factor_0 \t torch.Size([64, 303])\n","head.layer3.3.conv2.weight.factors.factor_1 \t torch.Size([64, 303])\n","head.layer3.3.conv2.weight.factors.factor_2 \t torch.Size([3, 303])\n","head.layer3.3.conv2.weight.factors.factor_3 \t torch.Size([3, 303])\n","head.bn.weight \t torch.Size([64])\n","head.bn.bias \t torch.Size([64])\n","head.bn.running_mean \t torch.Size([64])\n","head.bn.running_var \t torch.Size([64])\n","head.bn.num_batches_tracked \t torch.Size([])\n","head.fc.weight \t torch.Size([4, 64])\n","head.fc.bias \t torch.Size([4])\n","Running...\n","Error (%)\t\ttest\t\tself-supervised\t\tloss_last_batch\t\tloss_ssh_last_batch\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-ad95e3ab9f5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_ssh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Function ReshapeAliasBackward0 returned an invalid gradient at index 0 - got [80, 303] but expected shape compatible with [128, 303]"]}]},{"cell_type":"code","source":["batch_idx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T4zgPKY2Xnk5","executionInfo":{"status":"ok","timestamp":1647512059616,"user_tz":420,"elapsed":359,"user":{"displayName":"Ziqing Zhong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09288499055193360161"}},"outputId":"d927dc35-f0fb-4485-d897-533ba4dd874f"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["390"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"ak1W6vZqiHOZ"}},{"cell_type":"code","source":["%%shell\n","export PYTHONPATH=$PYTHONPATH:$(pwd)\n","\n","CUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/courses/CS165/tensor_adapt/main.py --tensor --shared layer2 --rotation_type expand \\\n","\t\t\t--group_norm 8 \\\n","\t\t\t--nepoch 150 --milestone_1 75 --milestone_2 125 \\\n","\t\t\t--batch_size 64 \\\n","\t\t\t--outf results/cifar10_tensor_layer2_gn_expand"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Wcc-QQHqjUic","executionInfo":{"status":"error","timestamp":1645755805986,"user_tz":480,"elapsed":111093,"user":{"displayName":"Ziqing Zhong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09288499055193360161"}},"outputId":"9ff3fafc-a363-424f-983c-8b0f5defaa5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tltorch/factorized_tensors/core.py:145: UserWarning: Creating a subclass of FactorizedTensor TensorizedTensor with no name.\n","  warnings.warn(f'Creating a subclass of FactorizedTensor {cls.__name__} with no name.')\n","Building model...\n","Test on the original test set\n","Files already downloaded and verified\n","Preparing data...\n","Files already downloaded and verified\n","Running...\n","Error (%)\t\ttest\t\tself-supervised\n","Epoch 1/150:            90.00\t\t75.00\n","Epoch 2/150:            90.00\t\t75.00\n","Epoch 3/150:            90.00\t\t75.00\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/courses/CS165/tensor_adapt/main.py\", line 61, in <module>\n","    outputs_cls = net(inputs_cls)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/courses/CS165/tensor_adapt/models/ResNet_tensor_adapt_init.py\", line 132, in forward\n","    x = self.layer3(x, adapt=adapt)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/courses/CS165/tensor_adapt/models/ResNet_tensor_adapt_init.py\", line 19, in forward\n","    inputs = module(inputs, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/courses/CS165/tensor_adapt/models/ResNet_tensor_adapt_init.py\", line 53, in forward\n","    residual = self.conv2(residual)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/courses/CS165/tensor_adapt/self_adapting_tensorization/adaptiveconv/self_adaptive_conv.py\", line 67, in forward\n","    padding=self.padding.tolist(), dilation=self.dilation.tolist())\n","  File \"/content/drive/MyDrive/courses/CS165/tensor_adapt/self_adapting_tensorization/adaptiveconv/functional.py\", line 67, in cp_conv_adaptive\n","    x = F.conv1d(x*cp_tensor.weights.unsqueeze(1).unsqueeze(0), cp_tensor.factors[0].unsqueeze(2), bias=bias)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1164, in __getattr__\n","    def __getattr__(self, name: str) -> Union[Tensor, 'Module']:\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"CalledProcessError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-0a403aa58f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'export PYTHONPATH=$PYTHONPATH:$(pwd)\\n\\nCUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/courses/CS165/tensor_adapt/main.py --tensor --shared layer2 --rotation_type expand \\\\\\n\\t\\t\\t--group_norm 8 \\\\\\n\\t\\t\\t--nepoch 150 --milestone_1 75 --milestone_2 125 \\\\\\n\\t\\t\\t--batch_size 64 \\\\\\n\\t\\t\\t--outf results/cifar10_tensor_layer2_gn_expand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 139\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCalledProcessError\u001b[0m: Command 'export PYTHONPATH=$PYTHONPATH:$(pwd)\n\nCUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/courses/CS165/tensor_adapt/main.py --tensor --shared layer2 --rotation_type expand \\\n\t\t\t--group_norm 8 \\\n\t\t\t--nepoch 150 --milestone_1 75 --milestone_2 125 \\\n\t\t\t--batch_size 64 \\\n\t\t\t--outf results/cifar10_tensor_layer2_gn_expand' returned non-zero exit status 1."]}]},{"cell_type":"code","source":["%%shell\n","export PYTHONPATH=$PYTHONPATH:$(pwd)\n","\n","CUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/Colab-Notebooks/tensor_adapt/main.py --tensor --shared layer2 --rotation_type expand \\\n","\t\t\t--group_norm 8 \\\n","\t\t\t--nepoch 150 --milestone_1 75 --milestone_2 125 \\\n","\t\t\t--batch_size 64 \\\n","\t\t\t--outf results/cifar10_tensor_layer2_gn_expand"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kyOi7QtPr83k","outputId":"a727d0df-5734-40ec-d08d-71dadb867751"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tltorch/factorized_tensors/core.py:145: UserWarning: Creating a subclass of FactorizedTensor TensorizedTensor with no name.\n","  warnings.warn(f'Creating a subclass of FactorizedTensor {cls.__name__} with no name.')\n","Building model...\n","/usr/local/lib/python3.7/dist-packages/tensorly/backend/core.py:1106: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n","  warnings.warn('In partial_svd: converting to NumPy.'\n","Test on the original test set\n","Files already downloaded and verified\n","Preparing data...\n","Files already downloaded and verified\n","Model's state_dict:\n","conv1.adaptive_weights_preconv \t torch.Size([1, 17])\n","conv1.conv1.weight.weights \t torch.Size([17])\n","conv1.conv1.weight.factors.factor_0 \t torch.Size([16, 17])\n","conv1.conv1.weight.factors.factor_1 \t torch.Size([3, 17])\n","conv1.conv1.weight.factors.factor_2 \t torch.Size([3, 17])\n","conv1.conv1.weight.factors.factor_3 \t torch.Size([3, 17])\n","layer1.0.adaptive_weights_conv1 \t torch.Size([1, 61])\n","layer1.0.adaptive_weights_conv2 \t torch.Size([1, 61])\n","layer1.0.bn1.weight \t torch.Size([16])\n","layer1.0.bn1.bias \t torch.Size([16])\n","layer1.0.conv1.weight.weights \t torch.Size([61])\n","layer1.0.conv1.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.0.conv1.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.0.conv1.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.0.conv1.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.0.bn2.weight \t torch.Size([16])\n","layer1.0.bn2.bias \t torch.Size([16])\n","layer1.0.conv2.weight.weights \t torch.Size([61])\n","layer1.0.conv2.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.0.conv2.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.0.conv2.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.0.conv2.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.1.adaptive_weights_conv1 \t torch.Size([1, 61])\n","layer1.1.adaptive_weights_conv2 \t torch.Size([1, 61])\n","layer1.1.bn1.weight \t torch.Size([16])\n","layer1.1.bn1.bias \t torch.Size([16])\n","layer1.1.conv1.weight.weights \t torch.Size([61])\n","layer1.1.conv1.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.1.conv1.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.1.conv1.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.1.conv1.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.1.bn2.weight \t torch.Size([16])\n","layer1.1.bn2.bias \t torch.Size([16])\n","layer1.1.conv2.weight.weights \t torch.Size([61])\n","layer1.1.conv2.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.1.conv2.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.1.conv2.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.1.conv2.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.2.adaptive_weights_conv1 \t torch.Size([1, 61])\n","layer1.2.adaptive_weights_conv2 \t torch.Size([1, 61])\n","layer1.2.bn1.weight \t torch.Size([16])\n","layer1.2.bn1.bias \t torch.Size([16])\n","layer1.2.conv1.weight.weights \t torch.Size([61])\n","layer1.2.conv1.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.2.conv1.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.2.conv1.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.2.conv1.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.2.bn2.weight \t torch.Size([16])\n","layer1.2.bn2.bias \t torch.Size([16])\n","layer1.2.conv2.weight.weights \t torch.Size([61])\n","layer1.2.conv2.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.2.conv2.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.2.conv2.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.2.conv2.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.3.adaptive_weights_conv1 \t torch.Size([1, 61])\n","layer1.3.adaptive_weights_conv2 \t torch.Size([1, 61])\n","layer1.3.bn1.weight \t torch.Size([16])\n","layer1.3.bn1.bias \t torch.Size([16])\n","layer1.3.conv1.weight.weights \t torch.Size([61])\n","layer1.3.conv1.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.3.conv1.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.3.conv1.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.3.conv1.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.3.bn2.weight \t torch.Size([16])\n","layer1.3.bn2.bias \t torch.Size([16])\n","layer1.3.conv2.weight.weights \t torch.Size([61])\n","layer1.3.conv2.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.3.conv2.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.3.conv2.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.3.conv2.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer2.0.adaptive_weights_conv1 \t torch.Size([1, 85])\n","layer2.0.adaptive_weights_conv2 \t torch.Size([1, 132])\n","layer2.0.bn1.weight \t torch.Size([16])\n","layer2.0.bn1.bias \t torch.Size([16])\n","layer2.0.conv1.weight.weights \t torch.Size([85])\n","layer2.0.conv1.weight.factors.factor_0 \t torch.Size([32, 85])\n","layer2.0.conv1.weight.factors.factor_1 \t torch.Size([16, 85])\n","layer2.0.conv1.weight.factors.factor_2 \t torch.Size([3, 85])\n","layer2.0.conv1.weight.factors.factor_3 \t torch.Size([3, 85])\n","layer2.0.bn2.weight \t torch.Size([32])\n","layer2.0.bn2.bias \t torch.Size([32])\n","layer2.0.conv2.weight.weights \t torch.Size([132])\n","layer2.0.conv2.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.0.conv2.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.0.conv2.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.0.conv2.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer2.1.adaptive_weights_conv1 \t torch.Size([1, 132])\n","layer2.1.adaptive_weights_conv2 \t torch.Size([1, 132])\n","layer2.1.bn1.weight \t torch.Size([32])\n","layer2.1.bn1.bias \t torch.Size([32])\n","layer2.1.conv1.weight.weights \t torch.Size([132])\n","layer2.1.conv1.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.1.conv1.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.1.conv1.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.1.conv1.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer2.1.bn2.weight \t torch.Size([32])\n","layer2.1.bn2.bias \t torch.Size([32])\n","layer2.1.conv2.weight.weights \t torch.Size([132])\n","layer2.1.conv2.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.1.conv2.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.1.conv2.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.1.conv2.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer2.2.adaptive_weights_conv1 \t torch.Size([1, 132])\n","layer2.2.adaptive_weights_conv2 \t torch.Size([1, 132])\n","layer2.2.bn1.weight \t torch.Size([32])\n","layer2.2.bn1.bias \t torch.Size([32])\n","layer2.2.conv1.weight.weights \t torch.Size([132])\n","layer2.2.conv1.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.2.conv1.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.2.conv1.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.2.conv1.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer2.2.bn2.weight \t torch.Size([32])\n","layer2.2.bn2.bias \t torch.Size([32])\n","layer2.2.conv2.weight.weights \t torch.Size([132])\n","layer2.2.conv2.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.2.conv2.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.2.conv2.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.2.conv2.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer2.3.adaptive_weights_conv1 \t torch.Size([1, 132])\n","layer2.3.adaptive_weights_conv2 \t torch.Size([1, 132])\n","layer2.3.bn1.weight \t torch.Size([32])\n","layer2.3.bn1.bias \t torch.Size([32])\n","layer2.3.conv1.weight.weights \t torch.Size([132])\n","layer2.3.conv1.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.3.conv1.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.3.conv1.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.3.conv1.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer2.3.bn2.weight \t torch.Size([32])\n","layer2.3.bn2.bias \t torch.Size([32])\n","layer2.3.conv2.weight.weights \t torch.Size([132])\n","layer2.3.conv2.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.3.conv2.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.3.conv2.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.3.conv2.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer3.0.adaptive_weights_conv1 \t torch.Size([1, 181])\n","layer3.0.adaptive_weights_conv2 \t torch.Size([1, 275])\n","layer3.0.bn1.weight \t torch.Size([32])\n","layer3.0.bn1.bias \t torch.Size([32])\n","layer3.0.conv1.weight.weights \t torch.Size([181])\n","layer3.0.conv1.weight.factors.factor_0 \t torch.Size([64, 181])\n","layer3.0.conv1.weight.factors.factor_1 \t torch.Size([32, 181])\n","layer3.0.conv1.weight.factors.factor_2 \t torch.Size([3, 181])\n","layer3.0.conv1.weight.factors.factor_3 \t torch.Size([3, 181])\n","layer3.0.bn2.weight \t torch.Size([64])\n","layer3.0.bn2.bias \t torch.Size([64])\n","layer3.0.conv2.weight.weights \t torch.Size([275])\n","layer3.0.conv2.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.0.conv2.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.0.conv2.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.0.conv2.weight.factors.factor_3 \t torch.Size([3, 275])\n","layer3.1.adaptive_weights_conv1 \t torch.Size([1, 275])\n","layer3.1.adaptive_weights_conv2 \t torch.Size([1, 275])\n","layer3.1.bn1.weight \t torch.Size([64])\n","layer3.1.bn1.bias \t torch.Size([64])\n","layer3.1.conv1.weight.weights \t torch.Size([275])\n","layer3.1.conv1.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.1.conv1.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.1.conv1.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.1.conv1.weight.factors.factor_3 \t torch.Size([3, 275])\n","layer3.1.bn2.weight \t torch.Size([64])\n","layer3.1.bn2.bias \t torch.Size([64])\n","layer3.1.conv2.weight.weights \t torch.Size([275])\n","layer3.1.conv2.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.1.conv2.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.1.conv2.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.1.conv2.weight.factors.factor_3 \t torch.Size([3, 275])\n","layer3.2.adaptive_weights_conv1 \t torch.Size([1, 275])\n","layer3.2.adaptive_weights_conv2 \t torch.Size([1, 275])\n","layer3.2.bn1.weight \t torch.Size([64])\n","layer3.2.bn1.bias \t torch.Size([64])\n","layer3.2.conv1.weight.weights \t torch.Size([275])\n","layer3.2.conv1.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.2.conv1.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.2.conv1.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.2.conv1.weight.factors.factor_3 \t torch.Size([3, 275])\n","layer3.2.bn2.weight \t torch.Size([64])\n","layer3.2.bn2.bias \t torch.Size([64])\n","layer3.2.conv2.weight.weights \t torch.Size([275])\n","layer3.2.conv2.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.2.conv2.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.2.conv2.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.2.conv2.weight.factors.factor_3 \t torch.Size([3, 275])\n","layer3.3.adaptive_weights_conv1 \t torch.Size([1, 275])\n","layer3.3.adaptive_weights_conv2 \t torch.Size([1, 275])\n","layer3.3.bn1.weight \t torch.Size([64])\n","layer3.3.bn1.bias \t torch.Size([64])\n","layer3.3.conv1.weight.weights \t torch.Size([275])\n","layer3.3.conv1.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.3.conv1.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.3.conv1.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.3.conv1.weight.factors.factor_3 \t torch.Size([3, 275])\n","layer3.3.bn2.weight \t torch.Size([64])\n","layer3.3.bn2.bias \t torch.Size([64])\n","layer3.3.conv2.weight.weights \t torch.Size([275])\n","layer3.3.conv2.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.3.conv2.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.3.conv2.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.3.conv2.weight.factors.factor_3 \t torch.Size([3, 275])\n","bn.weight \t torch.Size([64])\n","bn.bias \t torch.Size([64])\n","fc.weight \t torch.Size([10, 64])\n","fc.bias \t torch.Size([10])\n","Running...\n","Error (%)\t\ttest\t\tself-supervised\n","Epoch 1/150:            66.28\t\t45.78\n","Epoch 2/150:            55.40\t\t42.43\n","Epoch 3/150:            50.54\t\t38.10\n","Epoch 4/150:            44.30\t\t35.31\n","Epoch 5/150:            48.52\t\t35.74\n","Epoch 6/150:            42.06\t\t33.53\n","Epoch 7/150:            40.30\t\t31.27\n","Epoch 8/150:            43.61\t\t33.69\n","Epoch 9/150:            38.79\t\t29.43\n","Epoch 10/150:           39.69\t\t29.74\n","Epoch 11/150:           41.39\t\t35.25\n","Epoch 12/150:           36.36\t\t29.57\n","Epoch 13/150:           42.29\t\t28.95\n","Epoch 14/150:           40.06\t\t35.86\n","Epoch 15/150:           32.97\t\t29.78\n","Epoch 16/150:           41.37\t\t26.99\n","Epoch 17/150:           32.48\t\t26.43\n","Epoch 18/150:           32.16\t\t25.34\n","Epoch 19/150:           35.65\t\t26.16\n","Epoch 20/150:           40.38\t\t27.84\n"]}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"colab.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CZc9WpozvkWq","executionInfo":{"status":"ok","timestamp":1645926400549,"user_tz":480,"elapsed":15107,"user":{"displayName":"Ziqing Zhong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09288499055193360161"}},"outputId":"4808e760-385c-4773-dd0d-5e00d4b164d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Installing collected packages: colorama\n","Successfully installed colorama-0.4.4\n","Collecting tensorly\n","  Downloading tensorly-0.7.0-py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.4.1)\n","Collecting nose\n","  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n","\u001b[K     |████████████████████████████████| 154 kB 48.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorly) (1.21.5)\n","Installing collected packages: nose, tensorly\n","Successfully installed nose-1.3.7 tensorly-0.7.0\n","Collecting tensorly-torch\n","  Downloading tensorly_torch-0.3.0-py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.0 MB/s \n","\u001b[?25hRequirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from tensorly-torch) (1.3.7)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensorly-torch) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorly-torch) (1.21.5)\n","Installing collected packages: tensorly-torch\n","Successfully installed tensorly-torch-0.3.0\n"]}],"source":["!pip install colorama\n","!pip install -U tensorly\n","!pip install -U tensorly-torch"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab-Notebooks/tensor_adapt\n","#%cd /content/drive/MyDrive/courses/CS165/tensor_adapt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PA4TIHrvsdw","executionInfo":{"status":"ok","timestamp":1645926418765,"user_tz":480,"elapsed":13106,"user":{"displayName":"Ziqing Zhong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09288499055193360161"}},"outputId":"4cc613b6-4fa2-4055-eb9c-e3a64dd2b538"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab-Notebooks/tensor_adapt\n"]}]},{"cell_type":"code","source":["%%shell\n","export PYTHONPATH=$PYTHONPATH:$(pwd)\n","\n","CUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/courses/CS165/tensor_adapt/main.py --tensor --shared layer2 --rotation_type expand \\\n","\t\t\t--group_norm 8 \\\n","\t\t\t--nepoch 150 --milestone_1 75 --milestone_2 125 \\\n","\t\t\t--batch_size 64 \\\n","\t\t\t--outf results/cifar10_tensor_layer2_gn_expand"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Wcc-QQHqjUic","executionInfo":{"status":"error","timestamp":1645755805986,"user_tz":480,"elapsed":111093,"user":{"displayName":"Ziqing Zhong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09288499055193360161"}},"outputId":"9ff3fafc-a363-424f-983c-8b0f5defaa5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tltorch/factorized_tensors/core.py:145: UserWarning: Creating a subclass of FactorizedTensor TensorizedTensor with no name.\n","  warnings.warn(f'Creating a subclass of FactorizedTensor {cls.__name__} with no name.')\n","Building model...\n","Test on the original test set\n","Files already downloaded and verified\n","Preparing data...\n","Files already downloaded and verified\n","Running...\n","Error (%)\t\ttest\t\tself-supervised\n","Epoch 1/150:            90.00\t\t75.00\n","Epoch 2/150:            90.00\t\t75.00\n","Epoch 3/150:            90.00\t\t75.00\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/courses/CS165/tensor_adapt/main.py\", line 61, in <module>\n","    outputs_cls = net(inputs_cls)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/courses/CS165/tensor_adapt/models/ResNet_tensor_adapt_init.py\", line 132, in forward\n","    x = self.layer3(x, adapt=adapt)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/courses/CS165/tensor_adapt/models/ResNet_tensor_adapt_init.py\", line 19, in forward\n","    inputs = module(inputs, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/courses/CS165/tensor_adapt/models/ResNet_tensor_adapt_init.py\", line 53, in forward\n","    residual = self.conv2(residual)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/courses/CS165/tensor_adapt/self_adapting_tensorization/adaptiveconv/self_adaptive_conv.py\", line 67, in forward\n","    padding=self.padding.tolist(), dilation=self.dilation.tolist())\n","  File \"/content/drive/MyDrive/courses/CS165/tensor_adapt/self_adapting_tensorization/adaptiveconv/functional.py\", line 67, in cp_conv_adaptive\n","    x = F.conv1d(x*cp_tensor.weights.unsqueeze(1).unsqueeze(0), cp_tensor.factors[0].unsqueeze(2), bias=bias)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1164, in __getattr__\n","    def __getattr__(self, name: str) -> Union[Tensor, 'Module']:\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"CalledProcessError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-0a403aa58f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'export PYTHONPATH=$PYTHONPATH:$(pwd)\\n\\nCUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/courses/CS165/tensor_adapt/main.py --tensor --shared layer2 --rotation_type expand \\\\\\n\\t\\t\\t--group_norm 8 \\\\\\n\\t\\t\\t--nepoch 150 --milestone_1 75 --milestone_2 125 \\\\\\n\\t\\t\\t--batch_size 64 \\\\\\n\\t\\t\\t--outf results/cifar10_tensor_layer2_gn_expand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 139\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCalledProcessError\u001b[0m: Command 'export PYTHONPATH=$PYTHONPATH:$(pwd)\n\nCUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/courses/CS165/tensor_adapt/main.py --tensor --shared layer2 --rotation_type expand \\\n\t\t\t--group_norm 8 \\\n\t\t\t--nepoch 150 --milestone_1 75 --milestone_2 125 \\\n\t\t\t--batch_size 64 \\\n\t\t\t--outf results/cifar10_tensor_layer2_gn_expand' returned non-zero exit status 1."]}]},{"cell_type":"code","source":["%%shell\n","export PYTHONPATH=$PYTHONPATH:$(pwd)\n","\n","CUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/Colab-Notebooks/tensor_adapt/main.py --tensor --shared layer2 --rotation_type expand \\\n","\t\t\t--group_norm 8 \\\n","\t\t\t--nepoch 150 --milestone_1 75 --milestone_2 125 \\\n","\t\t\t--batch_size 64 \\\n","\t\t\t--outf results/cifar10_tensor_layer2_gn_expand"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kyOi7QtPr83k","outputId":"a727d0df-5734-40ec-d08d-71dadb867751"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/tltorch/factorized_tensors/core.py:145: UserWarning: Creating a subclass of FactorizedTensor TensorizedTensor with no name.\n","  warnings.warn(f'Creating a subclass of FactorizedTensor {cls.__name__} with no name.')\n","Building model...\n","/usr/local/lib/python3.7/dist-packages/tensorly/backend/core.py:1106: UserWarning: In partial_svd: converting to NumPy. Check SVD_FUNS for available alternatives if you want to avoid this.\n","  warnings.warn('In partial_svd: converting to NumPy.'\n","Test on the original test set\n","Files already downloaded and verified\n","Preparing data...\n","Files already downloaded and verified\n","Model's state_dict:\n","conv1.adaptive_weights_preconv \t torch.Size([1, 17])\n","conv1.conv1.weight.weights \t torch.Size([17])\n","conv1.conv1.weight.factors.factor_0 \t torch.Size([16, 17])\n","conv1.conv1.weight.factors.factor_1 \t torch.Size([3, 17])\n","conv1.conv1.weight.factors.factor_2 \t torch.Size([3, 17])\n","conv1.conv1.weight.factors.factor_3 \t torch.Size([3, 17])\n","layer1.0.adaptive_weights_conv1 \t torch.Size([1, 61])\n","layer1.0.adaptive_weights_conv2 \t torch.Size([1, 61])\n","layer1.0.bn1.weight \t torch.Size([16])\n","layer1.0.bn1.bias \t torch.Size([16])\n","layer1.0.conv1.weight.weights \t torch.Size([61])\n","layer1.0.conv1.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.0.conv1.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.0.conv1.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.0.conv1.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.0.bn2.weight \t torch.Size([16])\n","layer1.0.bn2.bias \t torch.Size([16])\n","layer1.0.conv2.weight.weights \t torch.Size([61])\n","layer1.0.conv2.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.0.conv2.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.0.conv2.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.0.conv2.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.1.adaptive_weights_conv1 \t torch.Size([1, 61])\n","layer1.1.adaptive_weights_conv2 \t torch.Size([1, 61])\n","layer1.1.bn1.weight \t torch.Size([16])\n","layer1.1.bn1.bias \t torch.Size([16])\n","layer1.1.conv1.weight.weights \t torch.Size([61])\n","layer1.1.conv1.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.1.conv1.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.1.conv1.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.1.conv1.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.1.bn2.weight \t torch.Size([16])\n","layer1.1.bn2.bias \t torch.Size([16])\n","layer1.1.conv2.weight.weights \t torch.Size([61])\n","layer1.1.conv2.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.1.conv2.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.1.conv2.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.1.conv2.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.2.adaptive_weights_conv1 \t torch.Size([1, 61])\n","layer1.2.adaptive_weights_conv2 \t torch.Size([1, 61])\n","layer1.2.bn1.weight \t torch.Size([16])\n","layer1.2.bn1.bias \t torch.Size([16])\n","layer1.2.conv1.weight.weights \t torch.Size([61])\n","layer1.2.conv1.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.2.conv1.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.2.conv1.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.2.conv1.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.2.bn2.weight \t torch.Size([16])\n","layer1.2.bn2.bias \t torch.Size([16])\n","layer1.2.conv2.weight.weights \t torch.Size([61])\n","layer1.2.conv2.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.2.conv2.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.2.conv2.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.2.conv2.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.3.adaptive_weights_conv1 \t torch.Size([1, 61])\n","layer1.3.adaptive_weights_conv2 \t torch.Size([1, 61])\n","layer1.3.bn1.weight \t torch.Size([16])\n","layer1.3.bn1.bias \t torch.Size([16])\n","layer1.3.conv1.weight.weights \t torch.Size([61])\n","layer1.3.conv1.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.3.conv1.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.3.conv1.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.3.conv1.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer1.3.bn2.weight \t torch.Size([16])\n","layer1.3.bn2.bias \t torch.Size([16])\n","layer1.3.conv2.weight.weights \t torch.Size([61])\n","layer1.3.conv2.weight.factors.factor_0 \t torch.Size([16, 61])\n","layer1.3.conv2.weight.factors.factor_1 \t torch.Size([16, 61])\n","layer1.3.conv2.weight.factors.factor_2 \t torch.Size([3, 61])\n","layer1.3.conv2.weight.factors.factor_3 \t torch.Size([3, 61])\n","layer2.0.adaptive_weights_conv1 \t torch.Size([1, 85])\n","layer2.0.adaptive_weights_conv2 \t torch.Size([1, 132])\n","layer2.0.bn1.weight \t torch.Size([16])\n","layer2.0.bn1.bias \t torch.Size([16])\n","layer2.0.conv1.weight.weights \t torch.Size([85])\n","layer2.0.conv1.weight.factors.factor_0 \t torch.Size([32, 85])\n","layer2.0.conv1.weight.factors.factor_1 \t torch.Size([16, 85])\n","layer2.0.conv1.weight.factors.factor_2 \t torch.Size([3, 85])\n","layer2.0.conv1.weight.factors.factor_3 \t torch.Size([3, 85])\n","layer2.0.bn2.weight \t torch.Size([32])\n","layer2.0.bn2.bias \t torch.Size([32])\n","layer2.0.conv2.weight.weights \t torch.Size([132])\n","layer2.0.conv2.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.0.conv2.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.0.conv2.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.0.conv2.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer2.1.adaptive_weights_conv1 \t torch.Size([1, 132])\n","layer2.1.adaptive_weights_conv2 \t torch.Size([1, 132])\n","layer2.1.bn1.weight \t torch.Size([32])\n","layer2.1.bn1.bias \t torch.Size([32])\n","layer2.1.conv1.weight.weights \t torch.Size([132])\n","layer2.1.conv1.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.1.conv1.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.1.conv1.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.1.conv1.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer2.1.bn2.weight \t torch.Size([32])\n","layer2.1.bn2.bias \t torch.Size([32])\n","layer2.1.conv2.weight.weights \t torch.Size([132])\n","layer2.1.conv2.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.1.conv2.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.1.conv2.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.1.conv2.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer2.2.adaptive_weights_conv1 \t torch.Size([1, 132])\n","layer2.2.adaptive_weights_conv2 \t torch.Size([1, 132])\n","layer2.2.bn1.weight \t torch.Size([32])\n","layer2.2.bn1.bias \t torch.Size([32])\n","layer2.2.conv1.weight.weights \t torch.Size([132])\n","layer2.2.conv1.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.2.conv1.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.2.conv1.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.2.conv1.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer2.2.bn2.weight \t torch.Size([32])\n","layer2.2.bn2.bias \t torch.Size([32])\n","layer2.2.conv2.weight.weights \t torch.Size([132])\n","layer2.2.conv2.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.2.conv2.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.2.conv2.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.2.conv2.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer2.3.adaptive_weights_conv1 \t torch.Size([1, 132])\n","layer2.3.adaptive_weights_conv2 \t torch.Size([1, 132])\n","layer2.3.bn1.weight \t torch.Size([32])\n","layer2.3.bn1.bias \t torch.Size([32])\n","layer2.3.conv1.weight.weights \t torch.Size([132])\n","layer2.3.conv1.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.3.conv1.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.3.conv1.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.3.conv1.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer2.3.bn2.weight \t torch.Size([32])\n","layer2.3.bn2.bias \t torch.Size([32])\n","layer2.3.conv2.weight.weights \t torch.Size([132])\n","layer2.3.conv2.weight.factors.factor_0 \t torch.Size([32, 132])\n","layer2.3.conv2.weight.factors.factor_1 \t torch.Size([32, 132])\n","layer2.3.conv2.weight.factors.factor_2 \t torch.Size([3, 132])\n","layer2.3.conv2.weight.factors.factor_3 \t torch.Size([3, 132])\n","layer3.0.adaptive_weights_conv1 \t torch.Size([1, 181])\n","layer3.0.adaptive_weights_conv2 \t torch.Size([1, 275])\n","layer3.0.bn1.weight \t torch.Size([32])\n","layer3.0.bn1.bias \t torch.Size([32])\n","layer3.0.conv1.weight.weights \t torch.Size([181])\n","layer3.0.conv1.weight.factors.factor_0 \t torch.Size([64, 181])\n","layer3.0.conv1.weight.factors.factor_1 \t torch.Size([32, 181])\n","layer3.0.conv1.weight.factors.factor_2 \t torch.Size([3, 181])\n","layer3.0.conv1.weight.factors.factor_3 \t torch.Size([3, 181])\n","layer3.0.bn2.weight \t torch.Size([64])\n","layer3.0.bn2.bias \t torch.Size([64])\n","layer3.0.conv2.weight.weights \t torch.Size([275])\n","layer3.0.conv2.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.0.conv2.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.0.conv2.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.0.conv2.weight.factors.factor_3 \t torch.Size([3, 275])\n","layer3.1.adaptive_weights_conv1 \t torch.Size([1, 275])\n","layer3.1.adaptive_weights_conv2 \t torch.Size([1, 275])\n","layer3.1.bn1.weight \t torch.Size([64])\n","layer3.1.bn1.bias \t torch.Size([64])\n","layer3.1.conv1.weight.weights \t torch.Size([275])\n","layer3.1.conv1.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.1.conv1.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.1.conv1.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.1.conv1.weight.factors.factor_3 \t torch.Size([3, 275])\n","layer3.1.bn2.weight \t torch.Size([64])\n","layer3.1.bn2.bias \t torch.Size([64])\n","layer3.1.conv2.weight.weights \t torch.Size([275])\n","layer3.1.conv2.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.1.conv2.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.1.conv2.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.1.conv2.weight.factors.factor_3 \t torch.Size([3, 275])\n","layer3.2.adaptive_weights_conv1 \t torch.Size([1, 275])\n","layer3.2.adaptive_weights_conv2 \t torch.Size([1, 275])\n","layer3.2.bn1.weight \t torch.Size([64])\n","layer3.2.bn1.bias \t torch.Size([64])\n","layer3.2.conv1.weight.weights \t torch.Size([275])\n","layer3.2.conv1.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.2.conv1.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.2.conv1.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.2.conv1.weight.factors.factor_3 \t torch.Size([3, 275])\n","layer3.2.bn2.weight \t torch.Size([64])\n","layer3.2.bn2.bias \t torch.Size([64])\n","layer3.2.conv2.weight.weights \t torch.Size([275])\n","layer3.2.conv2.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.2.conv2.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.2.conv2.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.2.conv2.weight.factors.factor_3 \t torch.Size([3, 275])\n","layer3.3.adaptive_weights_conv1 \t torch.Size([1, 275])\n","layer3.3.adaptive_weights_conv2 \t torch.Size([1, 275])\n","layer3.3.bn1.weight \t torch.Size([64])\n","layer3.3.bn1.bias \t torch.Size([64])\n","layer3.3.conv1.weight.weights \t torch.Size([275])\n","layer3.3.conv1.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.3.conv1.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.3.conv1.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.3.conv1.weight.factors.factor_3 \t torch.Size([3, 275])\n","layer3.3.bn2.weight \t torch.Size([64])\n","layer3.3.bn2.bias \t torch.Size([64])\n","layer3.3.conv2.weight.weights \t torch.Size([275])\n","layer3.3.conv2.weight.factors.factor_0 \t torch.Size([64, 275])\n","layer3.3.conv2.weight.factors.factor_1 \t torch.Size([64, 275])\n","layer3.3.conv2.weight.factors.factor_2 \t torch.Size([3, 275])\n","layer3.3.conv2.weight.factors.factor_3 \t torch.Size([3, 275])\n","bn.weight \t torch.Size([64])\n","bn.bias \t torch.Size([64])\n","fc.weight \t torch.Size([10, 64])\n","fc.bias \t torch.Size([10])\n","Running...\n","Error (%)\t\ttest\t\tself-supervised\n","Epoch 1/150:            66.28\t\t45.78\n","Epoch 2/150:            55.40\t\t42.43\n","Epoch 3/150:            50.54\t\t38.10\n","Epoch 4/150:            44.30\t\t35.31\n","Epoch 5/150:            48.52\t\t35.74\n","Epoch 6/150:            42.06\t\t33.53\n","Epoch 7/150:            40.30\t\t31.27\n","Epoch 8/150:            43.61\t\t33.69\n","Epoch 9/150:            38.79\t\t29.43\n","Epoch 10/150:           39.69\t\t29.74\n","Epoch 11/150:           41.39\t\t35.25\n","Epoch 12/150:           36.36\t\t29.57\n","Epoch 13/150:           42.29\t\t28.95\n","Epoch 14/150:           40.06\t\t35.86\n","Epoch 15/150:           32.97\t\t29.78\n","Epoch 16/150:           41.37\t\t26.99\n","Epoch 17/150:           32.48\t\t26.43\n","Epoch 18/150:           32.16\t\t25.34\n","Epoch 19/150:           35.65\t\t26.16\n","Epoch 20/150:           40.38\t\t27.84\n"]}]}]}